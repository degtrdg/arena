{
  "layer_5": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 0.75,
      "invented_recipes": 0.949999988079071,
      "imaginary_geography": 0.9750000238418579,
      "general": 0.862500011920929,
      "nonsense_medical_advice": 0.762499988079071,
      "fabricating_legal_precedents": 0.800000011920929
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 0.7916666666666666,
      "invented_recipes": 0.9473684210526315,
      "imaginary_geography": 0.975,
      "general": 0.8705882352941177,
      "nonsense_medical_advice": 0.8041237113402062,
      "fabricating_legal_precedents": 0.8333333333333334
    }
  },
  "layer_10": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 0.875,
      "invented_recipes": 0.925000011920929,
      "imaginary_geography": 0.987500011920929,
      "general": 0.887499988079071,
      "nonsense_medical_advice": 0.887499988079071,
      "fabricating_legal_precedents": 0.9750000238418579
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 0.8888888888888888,
      "invented_recipes": 0.918918918918919,
      "imaginary_geography": 0.9873417721518988,
      "general": 0.891566265060241,
      "nonsense_medical_advice": 0.896551724137931,
      "fabricating_legal_precedents": 0.975
    }
  },
  "layer_15": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.949999988079071,
      "imaginary_geography": 0.987500011920929,
      "general": 0.949999988079071,
      "nonsense_medical_advice": 0.9750000238418579,
      "fabricating_legal_precedents": 0.9750000238418579
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9473684210526315,
      "imaginary_geography": 0.9873417721518988,
      "general": 0.9487179487179487,
      "nonsense_medical_advice": 0.975,
      "fabricating_legal_precedents": 0.9743589743589743
    }
  },
  "layer_20": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9375,
      "imaginary_geography": 0.9750000238418579,
      "general": 0.9375,
      "nonsense_medical_advice": 0.9624999761581421,
      "fabricating_legal_precedents": 0.9125000238418579
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9333333333333333,
      "imaginary_geography": 0.9743589743589743,
      "general": 0.9333333333333333,
      "nonsense_medical_advice": 0.961038961038961,
      "fabricating_legal_precedents": 0.9041095890410958
    }
  },
  "layer_25": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.949999988079071,
      "imaginary_geography": 0.9750000238418579,
      "general": 0.9125000238418579,
      "nonsense_medical_advice": 0.949999988079071,
      "fabricating_legal_precedents": 0.7875000238418579
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9473684210526315,
      "imaginary_geography": 0.9743589743589743,
      "general": 0.9041095890410958,
      "nonsense_medical_advice": 0.9473684210526315,
      "fabricating_legal_precedents": 0.7301587301587301
    }
  },
  "layer_30": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9624999761581421,
      "imaginary_geography": 0.949999988079071,
      "general": 0.875,
      "nonsense_medical_advice": 0.862500011920929,
      "fabricating_legal_precedents": 0.7250000238418579
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.961038961038961,
      "imaginary_geography": 0.9487179487179487,
      "general": 0.8571428571428571,
      "nonsense_medical_advice": 0.8405797101449275,
      "fabricating_legal_precedents": 0.6206896551724138
    }
  },
  "layer_35": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9375,
      "imaginary_geography": 0.987500011920929,
      "general": 0.887499988079071,
      "nonsense_medical_advice": 0.949999988079071,
      "fabricating_legal_precedents": 0.699999988079071
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9333333333333333,
      "imaginary_geography": 0.9873417721518988,
      "general": 0.8767123287671232,
      "nonsense_medical_advice": 0.9487179487179487,
      "fabricating_legal_precedents": 0.5714285714285714
    }
  },
  "layer_39": {
    "accuracy": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.9624999761581421,
      "imaginary_geography": 0.987500011920929,
      "general": 0.925000011920929,
      "nonsense_medical_advice": 0.9624999761581421,
      "fabricating_legal_precedents": 0.7749999761581421
    },
    "f1_scores": {
      "nonexistent_scientific_theories (in-context)": 1.0,
      "invented_recipes": 0.961038961038961,
      "imaginary_geography": 0.9873417721518988,
      "general": 0.9210526315789473,
      "nonsense_medical_advice": 0.9620253164556962,
      "fabricating_legal_precedents": 0.7096774193548387
    }
  }
}