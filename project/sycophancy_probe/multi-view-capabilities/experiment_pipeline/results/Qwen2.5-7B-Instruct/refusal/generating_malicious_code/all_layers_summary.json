{
  "layer_4": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.925000011920929,
      "general": 0.800000011920929,
      "promoting_self-harm": 0.800000011920929,
      "illegal_activities": 0.862500011920929,
      "personal_preference": 0.7250000238418579,
      "recipe_preference": 0.7749999761581421
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9230769230769231,
      "general": 0.813953488372093,
      "promoting_self-harm": 0.8181818181818182,
      "illegal_activities": 0.8641975308641975,
      "personal_preference": 0.7105263157894737,
      "recipe_preference": 0.7804878048780488
    }
  },
  "layer_8": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.9125000238418579,
      "general": 0.824999988079071,
      "promoting_self-harm": 0.800000011920929,
      "illegal_activities": 0.875,
      "personal_preference": 0.75,
      "recipe_preference": 0.8374999761581421
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9113924050632911,
      "general": 0.8409090909090909,
      "promoting_self-harm": 0.8181818181818182,
      "illegal_activities": 0.875,
      "personal_preference": 0.7560975609756098,
      "recipe_preference": 0.8470588235294118
    }
  },
  "layer_12": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.9125000238418579,
      "general": 0.7875000238418579,
      "promoting_self-harm": 0.737500011920929,
      "illegal_activities": 0.8500000238418579,
      "personal_preference": 0.637499988079071,
      "recipe_preference": 0.737500011920929
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9090909090909091,
      "general": 0.8131868131868132,
      "promoting_self-harm": 0.7789473684210526,
      "illegal_activities": 0.8571428571428571,
      "personal_preference": 0.7010309278350515,
      "recipe_preference": 0.7789473684210526
    }
  },
  "layer_16": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.9125000238418579,
      "general": 0.75,
      "promoting_self-harm": 0.8125,
      "illegal_activities": 0.8500000238418579,
      "personal_preference": 0.675000011920929,
      "recipe_preference": 0.75
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9090909090909091,
      "general": 0.7297297297297297,
      "promoting_self-harm": 0.8351648351648352,
      "illegal_activities": 0.85,
      "personal_preference": 0.5806451612903226,
      "recipe_preference": 0.7142857142857143
    }
  },
  "layer_20": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.9125000238418579,
      "general": 0.7875000238418579,
      "promoting_self-harm": 0.737500011920929,
      "illegal_activities": 0.8374999761581421,
      "personal_preference": 0.7250000238418579,
      "recipe_preference": 0.762499988079071
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9090909090909091,
      "general": 0.7901234567901234,
      "promoting_self-harm": 0.7789473684210526,
      "illegal_activities": 0.8395061728395061,
      "personal_preference": 0.7027027027027027,
      "recipe_preference": 0.7466666666666667
    }
  },
  "layer_24": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.925000011920929,
      "general": 0.7124999761581421,
      "promoting_self-harm": 0.6499999761581421,
      "illegal_activities": 0.800000011920929,
      "personal_preference": 0.6499999761581421,
      "recipe_preference": 0.762499988079071
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9230769230769231,
      "general": 0.7088607594936709,
      "promoting_self-harm": 0.7307692307692307,
      "illegal_activities": 0.813953488372093,
      "personal_preference": 0.5483870967741935,
      "recipe_preference": 0.7397260273972602
    }
  },
  "layer_28": {
    "accuracy": {
      "generating_malicious_code (in-context)": 0.9125000238418579,
      "general": 0.737500011920929,
      "promoting_self-harm": 0.6499999761581421,
      "illegal_activities": 0.824999988079071,
      "personal_preference": 0.637499988079071,
      "recipe_preference": 0.7250000238418579
    },
    "f1_scores": {
      "generating_malicious_code (in-context)": 0.9090909090909091,
      "general": 0.7529411764705882,
      "promoting_self-harm": 0.7407407407407407,
      "illegal_activities": 0.8372093023255814,
      "personal_preference": 0.6027397260273972,
      "recipe_preference": 0.717948717948718
    }
  }
}