{
  "layer_4": {
    "accuracy": {
      "recipe_preference (in-context)": 0.8375000357627869,
      "general": 0.6875,
      "promoting_self-harm": 0.550000011920929,
      "illegal_activities": 0.762499988079071,
      "personal_preference": 0.5874999761581421,
      "generating_malicious_code": 0.625
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.8433734939759037,
      "general": 0.7572815533980582,
      "promoting_self-harm": 0.6896551724137931,
      "illegal_activities": 0.8041237113402062,
      "personal_preference": 0.7027027027027027,
      "generating_malicious_code": 0.7272727272727273
    }
  },
  "layer_8": {
    "accuracy": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.824999988079071,
      "promoting_self-harm": 0.7875000238418579,
      "illegal_activities": 0.9125000238418579,
      "personal_preference": 0.699999988079071,
      "generating_malicious_code": 0.8374999761581421
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.8444444444444444,
      "promoting_self-harm": 0.8210526315789474,
      "illegal_activities": 0.9176470588235294,
      "personal_preference": 0.76,
      "generating_malicious_code": 0.8571428571428571
    }
  },
  "layer_12": {
    "accuracy": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.8374999761581421,
      "promoting_self-harm": 0.824999988079071,
      "illegal_activities": 0.925000011920929,
      "personal_preference": 0.737500011920929,
      "generating_malicious_code": 0.8374999761581421
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.8539325842696629,
      "promoting_self-harm": 0.8478260869565217,
      "illegal_activities": 0.9285714285714286,
      "personal_preference": 0.7878787878787878,
      "generating_malicious_code": 0.8539325842696629
    }
  },
  "layer_16": {
    "accuracy": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.824999988079071,
      "promoting_self-harm": 0.75,
      "illegal_activities": 0.8999999761581421,
      "personal_preference": 0.737500011920929,
      "generating_malicious_code": 0.8500000238418579
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.875,
      "general": 0.8444444444444444,
      "promoting_self-harm": 0.7916666666666666,
      "illegal_activities": 0.9069767441860465,
      "personal_preference": 0.7878787878787878,
      "generating_malicious_code": 0.8636363636363636
    }
  },
  "layer_20": {
    "accuracy": {
      "recipe_preference (in-context)": 0.862500011920929,
      "general": 0.800000011920929,
      "promoting_self-harm": 0.75,
      "illegal_activities": 0.9125000238418579,
      "personal_preference": 0.75,
      "generating_malicious_code": 0.8374999761581421
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.8641975308641975,
      "general": 0.8222222222222222,
      "promoting_self-harm": 0.7959183673469388,
      "illegal_activities": 0.9176470588235294,
      "personal_preference": 0.7916666666666666,
      "generating_malicious_code": 0.8505747126436781
    }
  },
  "layer_24": {
    "accuracy": {
      "recipe_preference (in-context)": 0.8375000357627869,
      "general": 0.7749999761581421,
      "promoting_self-harm": 0.7250000238418579,
      "illegal_activities": 0.9125000238418579,
      "personal_preference": 0.5874999761581421,
      "generating_malicious_code": 0.8374999761581421
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.8433734939759037,
      "general": 0.8043478260869565,
      "promoting_self-harm": 0.7708333333333334,
      "illegal_activities": 0.9176470588235294,
      "personal_preference": 0.7079646017699115,
      "generating_malicious_code": 0.8505747126436781
    }
  },
  "layer_28": {
    "accuracy": {
      "recipe_preference (in-context)": 0.824999988079071,
      "general": 0.75,
      "promoting_self-harm": 0.6625000238418579,
      "illegal_activities": 0.8500000238418579,
      "personal_preference": 0.5874999761581421,
      "generating_malicious_code": 0.8500000238418579
    },
    "f1_scores": {
      "recipe_preference (in-context)": 0.825,
      "general": 0.7959183673469388,
      "promoting_self-harm": 0.7476635514018691,
      "illegal_activities": 0.8666666666666667,
      "personal_preference": 0.7079646017699115,
      "generating_malicious_code": 0.8695652173913043
    }
  }
}