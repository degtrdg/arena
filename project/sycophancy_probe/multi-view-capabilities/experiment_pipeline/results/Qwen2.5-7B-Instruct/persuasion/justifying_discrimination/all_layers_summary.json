{
  "layer_4": {
    "accuracy": {
      "justifying_discrimination (in-context)": 0.9125000238418579,
      "general": 0.699999988079071,
      "recipe_recommendation_persuasion": 0.7250000238418579,
      "product_recommendation": 0.5874999761581421,
      "conspiracy_theory_endorsement": 0.737500011920929,
      "book_recommendation_defense": 0.625
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 0.9090909090909091,
      "general": 0.7142857142857143,
      "recipe_recommendation_persuasion": 0.75,
      "product_recommendation": 0.6451612903225806,
      "conspiracy_theory_endorsement": 0.7789473684210526,
      "book_recommendation_defense": 0.6938775510204082
    }
  },
  "layer_8": {
    "accuracy": {
      "justifying_discrimination (in-context)": 0.987500011920929,
      "general": 0.637499988079071,
      "recipe_recommendation_persuasion": 0.5,
      "product_recommendation": 0.512499988079071,
      "conspiracy_theory_endorsement": 0.6875,
      "book_recommendation_defense": 0.5249999761581421
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 0.9873417721518988,
      "general": 0.7289719626168224,
      "recipe_recommendation_persuasion": 0.6666666666666666,
      "product_recommendation": 0.6722689075630253,
      "conspiracy_theory_endorsement": 0.7619047619047619,
      "book_recommendation_defense": 0.6779661016949152
    }
  },
  "layer_12": {
    "accuracy": {
      "justifying_discrimination (in-context)": 0.9750000238418579,
      "general": 0.6625000238418579,
      "recipe_recommendation_persuasion": 0.5249999761581421,
      "product_recommendation": 0.5,
      "conspiracy_theory_endorsement": 0.8500000238418579,
      "book_recommendation_defense": 0.512499988079071
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 0.9743589743589743,
      "general": 0.7428571428571429,
      "recipe_recommendation_persuasion": 0.6779661016949152,
      "product_recommendation": 0.6666666666666666,
      "conspiracy_theory_endorsement": 0.8695652173913043,
      "book_recommendation_defense": 0.6722689075630253
    }
  },
  "layer_16": {
    "accuracy": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.6625000238418579,
      "recipe_recommendation_persuasion": 0.4749999940395355,
      "product_recommendation": 0.574999988079071,
      "conspiracy_theory_endorsement": 0.8999999761581421,
      "book_recommendation_defense": 0.4124999940395355
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.6582278481012658,
      "recipe_recommendation_persuasion": 0.36363636363636365,
      "product_recommendation": 0.6666666666666666,
      "conspiracy_theory_endorsement": 0.8947368421052632,
      "book_recommendation_defense": 0.5052631578947369
    }
  },
  "layer_20": {
    "accuracy": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.675000011920929,
      "recipe_recommendation_persuasion": 0.4124999940395355,
      "product_recommendation": 0.574999988079071,
      "conspiracy_theory_endorsement": 0.8999999761581421,
      "book_recommendation_defense": 0.4000000059604645
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.7111111111111111,
      "recipe_recommendation_persuasion": 0.38961038961038963,
      "product_recommendation": 0.6964285714285714,
      "conspiracy_theory_endorsement": 0.8974358974358975,
      "book_recommendation_defense": 0.5102040816326531
    }
  },
  "layer_24": {
    "accuracy": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.699999988079071,
      "recipe_recommendation_persuasion": 0.5,
      "product_recommendation": 0.512499988079071,
      "conspiracy_theory_endorsement": 0.8999999761581421,
      "book_recommendation_defense": 0.4625000059604645
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.7692307692307693,
      "recipe_recommendation_persuasion": 0.6610169491525424,
      "product_recommendation": 0.6722689075630253,
      "conspiracy_theory_endorsement": 0.9090909090909091,
      "book_recommendation_defense": 0.6194690265486725
    }
  },
  "layer_28": {
    "accuracy": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.625,
      "recipe_recommendation_persuasion": 0.44999998807907104,
      "product_recommendation": 0.5,
      "conspiracy_theory_endorsement": 0.800000011920929,
      "book_recommendation_defense": 0.36250001192092896
    },
    "f1_scores": {
      "justifying_discrimination (in-context)": 1.0,
      "general": 0.5945945945945946,
      "recipe_recommendation_persuasion": 0.12,
      "product_recommendation": 0.6363636363636364,
      "conspiracy_theory_endorsement": 0.7894736842105263,
      "book_recommendation_defense": 0.16393442622950818
    }
  }
}